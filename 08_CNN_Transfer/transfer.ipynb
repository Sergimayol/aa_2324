{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1ozwAAiAyNHA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMy35hII78XT"
      },
      "source": [
        "# Transferència de coneixement\n",
        "\n",
        "L'objectiu d'avui és aprendre com podem emprar arquitectures ja existents per resoldre els nostres problemes.\n",
        "\n",
        "Com objectius secundaris tenim:\n",
        "\n",
        "1. Conèixer un nou conjunt de dades\n",
        "2. Entendre en profunditat com són dos dels models més emprats.\n",
        "3. Guardar i carregar xarxes neuronals\n",
        "\n",
        "## Dades\n",
        "\n",
        "El conjunt de dades [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) consta de 60.000 imatges en color de 32x32 pixels etiquetades en 10 classes, amb 6.000 imatges per classe. Hi ha 50.000 imatges d'entrenament i 10.000 imatges de _test_.\n",
        "\n",
        "\n",
        "Si voleu normalitzar les dades, a continuació teniu els valors ja calculats:\n",
        "\n",
        "  - mitjana: (0.4914, 0.4822, 0.4465)\n",
        "  - desviació típica: (0.247, 0.243, 0.261)\n",
        "\n",
        "Una altra funció que pot ser útil és `Resize(mida_desti)` que rep un enter com a paràmetre (la mida final).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjdicviT7-dg",
        "outputId": "a7afe3bc-4433-4636-c902-597c045d8b22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:07<00:00, 21391578.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ],
      "source": [
        "USE_ALEXNET = True\n",
        "\n",
        "train_batch_size = 64\n",
        "test_batch_size = 100\n",
        "\n",
        "img_size = (227, 227) if USE_ALEXNET else (224, 224)\n",
        "\n",
        "# Definim una seqüència (composició) de transformacions\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)), transforms.Resize(img_size)]\n",
        ")\n",
        "\n",
        "# Descarregam un dataset ja integrat en la llibreria Pytorch\n",
        "train_data = datasets.CIFAR10(\"./data\", train=True, download=True, transform=transform)\n",
        "test_data = datasets.CIFAR10(\"./data\", train=False, transform=transform)\n",
        "\n",
        "# Transformam les dades en l'estructura necessaria per entrenar una xarxa\n",
        "train_loader = torch.utils.data.DataLoader(train_data, train_batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, test_batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfcyKrSI46UK",
        "outputId": "374e5ff6-487a-4349-ec3e-b3456ad16712"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3),\n",
              " (10000, 32, 32, 3),\n",
              " (50000, 32, 32, 3),\n",
              " (10000, 32, 32, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "train_data.data.shape, test_data.data.shape, train_loader.dataset.data.shape, test_loader.dataset.data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dty0xrAh71Qw"
      },
      "source": [
        "## Transfer learning (Definició de la xarxa)\n",
        "\n",
        "En aquesta pràctica aplicarem la tècnica de _transfer learning_ a partir de dues de les xarxes més conegudes en el camp de visió per computador:\n",
        "\n",
        "-[**AlexNet**](https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf). (ImageNet Classification with Deep Convolutional Neural Network, 2012). La mida d'entrada de les imatges és de (227x227x3).Té prop de 60 milions de paràmetres entrenables.\n",
        "\n",
        "[**MobileNet v3**](https://pytorch.org/vision/main/models/mobilenetv3.html): és una arquitectura de xarxa neuronal convolucional dissenyada per a aplicacions de visió per ordinador en dispositius mòbils i sistemes encastats. Va ser desenvolupada per Google a la seva sèrie MobileNet, que se centra en l'eficiència i el rendiment de les xarxes neuronals en dispositius amb recursos limitats, com ara telèfons mòbils. Té dues versions: _small_ amb configuracions que van dels 2 als 5 milions de paràmetres; _large_ amb uns 6 milions de paràmetres. La mida d'entrada de les imatges és de (224x224x3)\n",
        "\n",
        "_Pytorch_ ens permet emprar aquestes xarxes de manera molt senzilla. [Més informació](https://pytorch.org/vision/stable/models.html).\n",
        "\n",
        "Si el model que cercam no es troba integrat dins la llibreria _Pytorch_ és bastant probable que si la trobem a Huggingface.\n",
        "\n",
        "Descarregarem AlexNet i a analitzar-la. En aquest cas no només ens baixam la seva arquitectura, també els pesos resultants de l'entrenament."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xaoFxi7cygHX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7262f6ec-35a5-427b-d2d2-78fdecc34710"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:01<00:00, 154MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Arquitectura AlexNet\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "alex = models.alexnet(weights=True)\n",
        "\n",
        "print(\"-\"*50)\n",
        "print(\"Arquitectura AlexNet\")\n",
        "print(\"-\"*50)\n",
        "alex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbTrkmaB46UL",
        "outputId": "b0913ab7-df26-4344-b9ca-4e0aff247286"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n",
            "100%|██████████| 9.83M/9.83M [00:00<00:00, 83.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Arquitectura MobileNet\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MobileNetV3(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2dNormActivation(\n",
              "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "      (2): Hardswish()\n",
              "    )\n",
              "    (1): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
              "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
              "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
              "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (4): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (5): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (6): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (7): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
              "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (8): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (9): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
              "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (10): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (11): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (12): Conv2dNormActivation(\n",
              "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "      (2): Hardswish()\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
              "    (1): Hardswish()\n",
              "    (2): Dropout(p=0.2, inplace=True)\n",
              "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "mobilenet  = models.mobilenet_v3_small(weights=True)\n",
        "\n",
        "print(\"-\"*50)\n",
        "print(\"Arquitectura MobileNet\")\n",
        "print(\"-\"*50)\n",
        "mobilenet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asepjghw2xED"
      },
      "source": [
        "Hi ha diverses maneres de realitzar la tècnica de _TransferLearning_ les dues més conegudes són:\n",
        "\n",
        " - **\"Congelar\"** els pesos de la part d'extracció de característiques (la part convolucional) i crear un nou classificador que s'adapti al nostre problema. Això implica que només entrenam una part de la xarxa.\n",
        " - **Reentrenar tota la xarxa**.\n",
        "\n",
        "Com que la nostra capacitat de càlcul és limitada, ens decantarem per la primera opció. Pensau que\n",
        "\n",
        " Per tal d'evitar el reentrenament necessitam canviar el valor de l'atribut  `requires_grad` al valor `False`. Aquest atribut és propietat de cada tensor. Podem recorrer els tensors mitjançant el següent codi:\n",
        " ```\n",
        "for param in alex.features.parameters():\n",
        "    param.requires_grad = False\n",
        " ```\n",
        " ### Feina a fer:\n",
        "\n",
        "- Bloc 1\n",
        " 1. Carregar la xarxa AlexNet i seleccionar la part d'extracció de característiques.\n",
        " 2. Definir un entorn seqüencial on implementarem el classificador de la xarxa.\n",
        " 3. Realitzar un entrenament: comparar rendiment (accuracy) i nombre de paràmetres.\n",
        " 4. Provar de guardar la vostra xarxa i tornar-la a carregar. Classificar una imatge del conjunt de test.\n",
        "- Bloc 2: Repetir el mateix procés que l'anterior amb la xarxa mobilenet v3.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gdE4awOl46UN"
      },
      "outputs": [],
      "source": [
        "for param in alex.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in mobilenet.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZrzR1-4Ny3hx"
      },
      "outputs": [],
      "source": [
        "\n",
        "base = alex if USE_ALEXNET else mobilenet\n",
        "\n",
        "my_net = nn.Sequential(base, nn.ReLU(), nn.Flatten(1, -1), nn.Linear(1000, 10), nn.Softmax(dim=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZH80zEa8IPW"
      },
      "source": [
        "## Entrenament\n",
        "\n",
        "[shhht](https://github.com/tqdm/tqdm) si voleu canviar el resum de l'entrenament per una barra de progrés"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eJiXfzTM7e8d"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch, log_interval=100, verbose=True):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    loss_v = 0\n",
        "\n",
        "    for batch_idx, (data, target) in (t:= tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch}\")):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target, reduction='mean')\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0 and verbose:\n",
        "            t.set_description('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Average: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item(), loss.item()/ len(data)))\n",
        "        loss_v += loss.item()\n",
        "\n",
        "    loss_v /= len(train_loader.dataset)\n",
        "    print('\\nTrain set: Average loss: {:.4f}\\n'.format(loss_v))\n",
        "\n",
        "    return loss_v\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in tqdm(test_loader, total=len(test_loader), desc=\"Test\"):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.cross_entropy(output, target, reduction='mean')\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    return test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "llV5gCGU7jIT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49b9a6a8-c7e2-40f5-eec7-138b47ef97df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Parameters  10010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 0:   0%|          | 0/782 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Train Epoch: 0 [44800/50000 (90%)]\tLoss: 1.798964, Average: 0.028109: 100%|██████████| 782/782 [03:10<00:00,  4.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train set: Average loss: 0.0281\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 100/100 [00:32<00:00,  3.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0173, Accuracy: 7448/10000 (74%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.757456, Average: 0.027460: 100%|██████████| 782/782 [02:41<00:00,  4.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train set: Average loss: 0.0272\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 100/100 [00:31<00:00,  3.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0170, Accuracy: 7609/10000 (76%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.790611, Average: 0.027978: 100%|██████████| 782/782 [02:36<00:00,  4.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train set: Average loss: 0.0270\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 100/100 [00:31<00:00,  3.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0170, Accuracy: 7633/10000 (76%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(33)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "epochs = 3\n",
        "lr = 1e-3\n",
        "\n",
        "model = my_net.to(device)\n",
        "\n",
        "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"Parameters \", pytorch_total_params)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# Guardam el valor de pèrdua mig de cada iteració (època)\n",
        "train_l = np.zeros((epochs))\n",
        "test_l = np.zeros((epochs))\n",
        "\n",
        "for epoch in range(0, epochs):\n",
        "    train_l[epoch] = train(model, device, train_loader, optimizer, epoch)\n",
        "    test_l[epoch]  = test(model, device, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "AJzao3Z7Jlc_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "d0f82d5e-275c-4e3c-c7a9-7744a9b77082"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.title(\"Resultats de l'entrenament\")\n",
        "plt.plot(range(1, (epochs + 1)), train_l,  c=\"red\", label=\"train\")\n",
        "plt.plot(range(1,  (epochs + 1)), test_l,  c=\"green\", label=\"test\")\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alex = models.alexnet(weights=True)\n",
        "\n",
        "for ft in alex.features.parameters():\n",
        "    ft.requires_grad = False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKBweS4g-Vrb",
        "outputId": "18854379-844d-4e2e-c7d0-b125d20dc808"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_net = nn.Sequential(\n",
        "    alex.features,\n",
        "    alex.avgpool,\n",
        "    nn.Dropout(p=0.5, inplace=False),\n",
        "    nn.Flatten(1, -1),\n",
        "    nn.Linear(in_features=9216, out_features=4096),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=4096, out_features=1000),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(1000, 10),\n",
        "    nn.Softmax(dim=1)\n",
        ")\n",
        "my_net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BEYk4n3-jzm",
        "outputId": "5885e349-4a67-4dd2-d56a-22ef0f7d2bf8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (1): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (2): Dropout(p=0.5, inplace=False)\n",
              "  (3): Flatten(start_dim=1, end_dim=-1)\n",
              "  (4): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "  (5): ReLU()\n",
              "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  (7): ReLU()\n",
              "  (8): Linear(in_features=1000, out_features=10, bias=True)\n",
              "  (9): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(33)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "epochs = 4\n",
        "lr = 1e-3\n",
        "\n",
        "model = my_net.to(device)\n",
        "\n",
        "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"Parameters \", pytorch_total_params)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# Guardam el valor de pèrdua mig de cada iteració (època)\n",
        "train_l = np.zeros((epochs))\n",
        "test_l = np.zeros((epochs))\n",
        "\n",
        "for epoch in range(0, epochs):\n",
        "    train_l[epoch] = train(model, device, train_loader, optimizer, epoch)\n",
        "    test_l[epoch]  = test(model, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QmC97ADAkkq",
        "outputId": "28d34f4b-cab0-4d20-cd29-b999629d07df"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Parameters  41859842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch: 0 [44800/50000 (90%)]\tLoss: 2.336151, Average: 0.036502: 100%|██████████| 782/782 [02:47<00:00,  4.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train set: Average loss: 0.0369\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 100/100 [00:31<00:00,  3.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0236, Accuracy: 1000/10000 (10%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 2.336151, Average: 0.036502: 100%|██████████| 782/782 [02:45<00:00,  4.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train set: Average loss: 0.0369\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 100/100 [00:30<00:00,  3.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0236, Accuracy: 1000/10000 (10%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 2.336151, Average: 0.036502: 100%|██████████| 782/782 [02:45<00:00,  4.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train set: Average loss: 0.0369\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 100/100 [00:30<00:00,  3.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0236, Accuracy: 1000/10000 (10%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 2.336151, Average: 0.036502: 100%|██████████| 782/782 [02:46<00:00,  4.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train set: Average loss: 0.0369\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 100/100 [00:30<00:00,  3.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0236, Accuracy: 1000/10000 (10%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_l_2 = []\n",
        "test_l_2 =[]\n",
        "for epoch in range(epochs, epochs + 3):\n",
        "    train_l_2.append(train(model, device, train_loader, optimizer, epoch))\n",
        "    test_l_2.append(test(model, device, test_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6wvoaAnDlqh",
        "outputId": "e8ac819a-4ce5-4224-9167-9bcdea92fff5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.851429, Average: 0.028929: 100%|██████████| 782/782 [02:39<00:00,  4.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train set: Average loss: 0.0284\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 100/100 [00:31<00:00,  3.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0182, Accuracy: 6414/10000 (64%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 1.820270, Average: 0.028442: 100%|██████████| 782/782 [02:43<00:00,  4.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train set: Average loss: 0.0284\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 100/100 [00:33<00:00,  2.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0181, Accuracy: 6505/10000 (65%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 1.836020, Average: 0.028688: 100%|██████████| 782/782 [02:46<00:00,  4.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train set: Average loss: 0.0284\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 100/100 [00:31<00:00,  3.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0181, Accuracy: 6512/10000 (65%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}