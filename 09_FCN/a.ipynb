{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 139811\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class TinyFCN(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(TinyFCN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(kernel_size=1, stride=1),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(kernel_size=1, stride=2, padding=1),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=num_classes, kernel_size=1),\n",
    "        )\n",
    "\n",
    "\n",
    "# Print the number of parameters in the model\n",
    "model = TinyFCN()\n",
    "print('Number of parameters: {}'.format(sum([p.numel() for p in model.parameters()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 371073\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class FCNRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FCNRegression, self).__init__()\n",
    "\n",
    "        # Capas convolucionales\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Capas totalmente convolucionales para regresión\n",
    "        self.fc = nn.Conv2d(256, 1, kernel_size=1)  # Última capa con un solo canal de salida para regresión\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pasar por las capas convolucionales\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "\n",
    "        # Pasar por la capa totalmente convolucional para regresión\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Crear una instancia del modelo\n",
    "model = FCNRegression()\n",
    "\n",
    "print('Number of parameters: {}'.format(sum([p.numel() for p in model.parameters()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Sergi/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 35312984\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class MYNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MYNet, self).__init__()\n",
    "        self.model = torch.hub.load(\"pytorch/vision:v0.10.0\", \"fcn_resnet50\", pretrained=True)\n",
    "        self.model.classifier[4] = nn.Conv2d(512, 3, kernel_size=(1, 1), stride=(1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)[\"out\"]\n",
    "\n",
    "\n",
    "model = MYNet()\n",
    "print(\"Number of parameters: {}\".format(sum([p.numel() for p in model.parameters()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval=100, verbose=True):\n",
    "    model.train()\n",
    "    loss_v = 0\n",
    "\n",
    "    for batch_idx, (data, target) in (t := tqdm(enumerate(train_loader), total=len(train_loader), disable=not verbose)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0 and verbose:\n",
    "            t.set_description(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(data),\n",
    "                    len(train_loader.dataset),\n",
    "                    100.0 * batch_idx / len(train_loader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "        loss_v += loss.item()\n",
    "    loss_v /= len(train_loader.dataset)\n",
    "    print(\"\\nTrain set: Average loss: {:.4f}\\n\".format(loss_v))\n",
    "    return loss_v\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, epoch, verbose=True):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader, total=len(test_loader), disable=not verbose, desc=f\"Testing: {epoch}\"):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction=\"sum\").item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # obtener el índice de la probabilidad máxima\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
    "            test_loss, correct, len(test_loader.dataset), 100.0 * correct / len(test_loader.dataset)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "\n",
    "path_train = os.path.join(os.getcwd(), \"data\", \"aixi_shape_256_texture\", \"train\")\n",
    "\n",
    "files = os.listdir(path_train)\n",
    "\n",
    "img_files = [os.path.join(path_train, p) for p in files if p.endswith(\".png\")]\n",
    "label_files = [os.path.join(path_train, \"gt\", p) for p in files if p.endswith(\".png\")]\n",
    "\n",
    "\n",
    "class AIXI_Shape(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        super().__init__()\n",
    "        self.paths = images\n",
    "        self.labels = labels\n",
    "        self.len = len(self.paths)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.paths[index]\n",
    "        label_path = self.labels[index]\n",
    "        image = cv2.imread(path)\n",
    "        label = cv2.imread(label_path)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            label = self.transform(label)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# image normalization\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[1.9491e-05, 4.0427e-05, 3.6870e-05], std=[0.0003, 0.0004, 0.0004]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# creació dels conjunts d'entrenament i test\n",
    "train_ds = AIXI_Shape(img_files, label_files, transform)\n",
    "# El test l'heu de crear vosaltres\n",
    "train_dl = DataLoader(train_ds, batch_size=64)\n",
    "train_dl.dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "path_train = os.path.join(os.getcwd(), \"data\", \"aixi_shape_256_texture\", \"val\")\n",
    "\n",
    "test_files = os.listdir(path_train)\n",
    "\n",
    "test_img_files = [os.path.join(path_train, p) for p in files if p.endswith(\".png\")]\n",
    "test_label_files = [os.path.join(path_train, \"gt\", p) for p in files if p.endswith(\".png\")]\n",
    "\n",
    "test_ds = AIXI_Shape(test_img_files, test_label_files, transform)\n",
    "test_dl = DataLoader(test_ds, batch_size=64)\n",
    "test_dl.dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Sergi/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "Train Epoch: 0 [9600/10000 (96%)]\tLoss: -12.073175: 100%|██████████| 157/157 [08:12<00:00,  3.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set: Average loss: -0.0775\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 0:   0%|          | 0/157 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[64, 1, 256, 256]' is invalid for input of size 12582912",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Sergi\\Documents\\GitHub\\aa_2324\\09_FCN\\a.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sergi/Documents/GitHub/aa_2324/09_FCN/a.ipynb#W5sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m optimizer \u001b[39m=\u001b[39m opt_adam \u001b[39mif\u001b[39;00m epoch \u001b[39m<\u001b[39m \u001b[39m10\u001b[39m \u001b[39melse\u001b[39;00m opt_sgd\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sergi/Documents/GitHub/aa_2324/09_FCN/a.ipynb#W5sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m train_l[epoch] \u001b[39m=\u001b[39m train(model, device, train_dl, optimizer, epoch, log_interval\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Sergi/Documents/GitHub/aa_2324/09_FCN/a.ipynb#W5sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m test_l[epoch] \u001b[39m=\u001b[39m test(model, device, test_dl, epoch)\n",
      "\u001b[1;32mc:\\Users\\Sergi\\Documents\\GitHub\\aa_2324\\09_FCN\\a.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sergi/Documents/GitHub/aa_2324/09_FCN/a.ipynb#W5sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m         test_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(output, target, reduction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msum\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sergi/Documents/GitHub/aa_2324/09_FCN/a.ipynb#W5sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m         pred \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)  \u001b[39m# obtener el índice de la probabilidad máxima\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Sergi/Documents/GitHub/aa_2324/09_FCN/a.ipynb#W5sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m         correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39meq(target\u001b[39m.\u001b[39;49mview_as(pred))\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sergi/Documents/GitHub/aa_2324/09_FCN/a.ipynb#W5sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m test_loss \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(test_loader\u001b[39m.\u001b[39mdataset)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sergi/Documents/GitHub/aa_2324/09_FCN/a.ipynb#W5sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sergi/Documents/GitHub/aa_2324/09_FCN/a.ipynb#W5sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mTest set: Average loss: \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m, Accuracy: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{:.0f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sergi/Documents/GitHub/aa_2324/09_FCN/a.ipynb#W5sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m         test_loss, correct, \u001b[39mlen\u001b[39m(test_loader\u001b[39m.\u001b[39mdataset), \u001b[39m100.0\u001b[39m \u001b[39m*\u001b[39m correct \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(test_loader\u001b[39m.\u001b[39mdataset)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sergi/Documents/GitHub/aa_2324/09_FCN/a.ipynb#W5sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sergi/Documents/GitHub/aa_2324/09_FCN/a.ipynb#W5sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[64, 1, 256, 256]' is invalid for input of size 12582912"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(33)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device {device}\")\n",
    "\n",
    "epochs = 15\n",
    "lr = 10e-4\n",
    "\n",
    "model = MYNet().to(device)\n",
    "# Freeze the layers except the classifier\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# print(model)\n",
    "\n",
    "opt_adam = optim.Adam(model.parameters(), lr=lr)\n",
    "opt_sgd = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "# Guardam el valor de pèrdua mig de cada iteració (època)\n",
    "train_l = np.zeros((epochs))\n",
    "test_l = np.zeros((epochs))\n",
    "\n",
    "# Bucle d'entrenament\n",
    "for epoch in range(0, epochs):\n",
    "    optimizer = opt_adam if epoch < 10 else opt_sgd\n",
    "    train_l[epoch] = train(model, device, train_dl, optimizer, epoch, log_interval=10)\n",
    "    test_l[epoch] = test(model, device, test_dl, epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
